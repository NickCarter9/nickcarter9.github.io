{"pages":[{"title":"About","text":"I am Nick. I have great passion to work in the computer science field.Work in Qisda Corporation as android developer. Majored in App UI Application. Here’s my first blog, sharing my research and thought. Any comment and sharing will be welcome. Links GitHub Page nickthomas55@gmail.com Technical Program Language:C/C++/C#、JAVA、Java Script、QML、Swift、Kotiln、SQL Android Application:UI Design、LiveWallper(RenderScript)、Bluetooth、Bluetooth Low Energy、WiFi、Ethernet、TCP &amp; UDP、Http/Https、Customized LockScreen by xml design、Customized Launcher、SQLiteDatabase、Decrypt/Encrypt、OpenGL、Recorder、Customized Email、 ADB Command Line、JPush API、Facebook API、Twitter API、Plurk API、VLCPlayer API、SQLCipher API、Web Socket、Time Syncchronize、MQTT Server/Client Android Framework:Bluetooth、Ethernet、BT PAN Network、Customized LockScreen by xml design Android JNI Level:BT PAN Network、Simulate touch、move action by the instruction of WiFi or BT information. iOS Application:UI Design、Bluetooth Low Energy、Database、Plot Draw、Web Socket Web Development:UI Design、SQL Employment 2013.3 - until nowQisda Corporation, Principal Engineer 2010.8 - 2013.3BenQ Corporation, Senior Engineer 2009.10 - 2010.8Research Assistant in NCCU","link":"/about/index.html"}],"posts":[{"title":"iOS - NavigationItem - Bar Button Item","text":"When developing bluetooth project, we use a button at NavigationItem to control start and stop searching bluetooth device. Step 1: Add Bar Button Item Add Bar Button Item at Navigation Item and set the System item is Search. Step 2: Link UI and source code Step 3: Control BarButtonItem Icon 123456789private func changeToStopButton() { let stopScanningButton = UIBarButtonItem( barButtonSystemItem: UIBarButtonSystemItem.Stop, target: self, action: #selector(ViewController.stopScan)); self.navigationItem.rightBarButtonItem = stopScanningButton;}private func changeToScanButton() { let scanButton = UIBarButtonItem( barButtonSystemItem: UIBarButtonSystemItem.Search, target: self, action: #selector(ViewController.startScan)); self.navigationItem.rightBarButtonItem = scanButton;} Source Code 1234567891011121314151617181920212223242526272829303132333435363738import UIKitclass ViewController: UIViewController { var mBtManager : BtManager!; override func viewDidLoad() { super.viewDidLoad() mBtManager = BtManager(); } override func didReceiveMemoryWarning() { super.didReceiveMemoryWarning() } @IBAction func prepareScan(sender: AnyObject) { startScan(); } func startScan() { mBtManager.startToScan(); changeToStopButton(); } func stopScan() { mBtManager.stopScanning(); changeToScanButton(); } private func changeToStopButton() { let stopScanningButton = UIBarButtonItem( barButtonSystemItem: UIBarButtonSystemItem.Stop, target: self, action: #selector(ViewController.stopScan)); self.navigationItem.rightBarButtonItem = stopScanningButton; } private func changeToScanButton() { let scanButton = UIBarButtonItem( barButtonSystemItem: UIBarButtonSystemItem.Search, target: self, action: #selector(ViewController.startScan)); self.navigationItem.rightBarButtonItem = scanButton; }}","link":"/2016/07/06/2016/2016_07_06-ios-navigationbar_baritem/"},{"title":"iOS - Spinner","text":"iOS doesn’t support spinner widget.Some website use TextField to simulate spinner widget, but it occurs a problem that can’t hide virtual keyboard. Therefore I choose Button widget to implement it. Step 1: Init Button Widget Change text color to block, and add a icon. Step 2: Create PickerView Setup the content of spinner. 12345678910@IBAction func openMenu(sender: AnyObject) { showPicker() } internal func showPicker() { let pickerView = UIPickerView(frame:CGRectMake(0, 0, 200, 100)) pickerView.showsSelectionIndicator = true pickerView.dataSource = self pickerView.delegate = self} Setup count of cloumns and rows. 123456789extension ViewController : UIPickerViewDataSource { func pickerView(pickerView: UIPickerView, numberOfRowsInComponent component: Int) -&gt; Int { return self.dataArray.count } func numberOfComponentsInPickerView(pickerView: UIPickerView) -&gt; Int { return 1 }} Setup content and update ui when picking an item. 123456789extension ViewController : UIPickerViewDelegate { func pickerView(pickerView: UIPickerView, titleForRow row: Int, forComponent component: Int) -&gt; String? { return self.dataArray[row] } func pickerView(pickerView: UIPickerView, didSelectRow row: Int, inComponent component: Int) { //update UI }} Step 3: Create ToolBar Setup the position of picker view. 123self.sortView = UIToolbar(frame:CGRectMake(menuField.frame.origin.x, menuField.frame.origin.y + menuField.frame.height, 200, 130)) self.sortView!.barStyle = UIBarStyle.Defaultself.sortView!.backgroundColor = UIColor.blackColor(); Setup the done button. 123456 let doneButton = UIBarButtonItem(title: &quot;Done&quot;, style: UIBarButtonItemStyle.Done, target: self, action: #selector(ViewController.doneClicked))//Using flexibleSpace to setup the position of Done buttonlet flexibleSpace = UIBarButtonItem(barButtonSystemItem: UIBarButtonSystemItem.FlexibleSpace, target: nil, action: nil)self.sortView!.setItems([flexibleSpace, doneButton, flexibleSpace], animated: true) We hide picker view after choosing an item. 1234567func doneClicked() { if (nil != self.sortView) { self.sortView!.removeFromSuperview() } else { //nothing else } } Step 4: Add PickerView into spinner. 1234//add pickerview into Pull-Down Menuself.sortView!.addSubview(pickerView);//show Pull-Down Menuself.view.addSubview(self.sortView!) Result Source Code 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081import UIKitclass ViewController: UIViewController { @IBOutlet weak var menuField: UIButton! var sortView : UIToolbar? let dataArray = [&quot;綠茶&quot;, &quot;紅茶&quot;, &quot;烏龍茶&quot;] override func viewDidLoad() { super.viewDidLoad() } override func didReceiveMemoryWarning() { super.didReceiveMemoryWarning() } @IBAction func openMenu(sender: AnyObject) { showPicker() } internal func showPicker() { //Create PickerView let pickerView = UIPickerView(frame:CGRectMake(0, 0, 200, 100)) pickerView.showsSelectionIndicator = true pickerView.dataSource = self pickerView.delegate = self //Create Pull-Down Menu, and adjust position self.sortView = UIToolbar(frame:CGRectMake(menuField.frame.origin.x, menuField.frame.origin.y + menuField.frame.height, 200, 130)) self.sortView!.barStyle = UIBarStyle.Default self.sortView!.backgroundColor = UIColor.blackColor(); //Create Done Button let doneButton = UIBarButtonItem(title: &quot;Done&quot;, style: UIBarButtonItemStyle.Done, target: self, action: #selector(ViewController.doneClicked)) //Using flexibleSpace to setup the position of Done button let flexibleSpace = UIBarButtonItem(barButtonSystemItem: UIBarButtonSystemItem.FlexibleSpace, target: nil, action: nil) self.sortView!.setItems([flexibleSpace, doneButton, flexibleSpace], animated: true) //add pickerview into Pull-Down Menu self.sortView!.addSubview(pickerView); //show Pull-Down Menu self.view.addSubview(self.sortView!) } func doneClicked() { if (nil != self.sortView) { self.sortView!.removeFromSuperview() } else { //nothing else } }} extension ViewController : UIPickerViewDataSource { func pickerView(pickerView: UIPickerView, numberOfRowsInComponent component: Int) -&gt; Int { return self.dataArray.count } func numberOfComponentsInPickerView(pickerView: UIPickerView) -&gt; Int { return 1 }} extension ViewController : UIPickerViewDelegate { func pickerView(pickerView: UIPickerView, titleForRow row: Int, forComponent component: Int) -&gt; String? { return self.dataArray[row] } func pickerView(pickerView: UIPickerView, didSelectRow row: Int, inComponent component: Int) { //update UI }}","link":"/2016/10/13/2016/2016_10_13-spinner/"},{"title":"iOS - PageViewController &amp; SegmentedControl","text":"In this article, we use SegmentedControl and PageViewController to change page. Step 1: UI Design Add Segmented Control in main page. Add two ViewController and setup storyboard id : firstPage and secondPage. Step 2: Reference SegmentedControl Setup SegmentedControl object and click event in ViewController.swift. Using UISegmentedControl.selectedSegmentIndex to get the current tab’s id. Step 3: Setup PageViewController Setup PageView Content Add a PageViewController 1var pageController: UIPageViewController! Scroll view to change page. 1pageController = UIPageViewController(transitionStyle: .Scroll, navigationOrientation:.Horizontal, options: nil) Show the position of PageView. 1pageController!.view.frame = CGRectMake(0, mPageSegment.frame.origin.y + mPageSegment.frame.height, view.frame.size.width, view.frame.size.height); Setup main page. 12currentPageIndex = 0; pageController.setViewControllers([viewControllers.objectAtIndex(currentPageIndex) as! UIViewController], direction: .Forward, animated: false) {(isFinished:Bool) -&gt; Void in} Monitoring the changed event of UIPageViewControllerDelegate and UIPageViewControllerDataSource. 123456789101112131415161718192021222324pageController.delegate = self;pageController.dataSource = self;extension ViewController: UIPageViewControllerDataSource { func pageViewController(pageViewController: UIPageViewController, viewControllerBeforeViewController viewController: UIViewController) -&gt; UIViewController? { return nil } func pageViewController(pageViewController: UIPageViewController, viewControllerAfterViewController viewController: UIViewController) -&gt; UIViewController? { return nil }} extension ViewController: UIPageViewControllerDelegate { func pageViewController(pageViewController: UIPageViewController, }} Add the PageViewController. 12self.addChildViewController(pageController)self.view.addSubview(pageController.view) Step 4: Setup content when changing page When scrolling page from left to right, if the previous page index smaller than 0, return nil. 123456789func pageViewController(pageViewController: UIPageViewController, viewControllerBeforeViewController viewController: UIViewController) -&gt; UIViewController? { currentPageIndex = viewController.view.tag let pageIndex = viewController.view.tag - 1; if pageIndex &lt; 0 { return nil } return viewControllers[pageIndex] as? UIViewController } When scrolling page from right to left, if the net page index larger than total page, return nil. 123456789func pageViewController(pageViewController: UIPageViewController, viewControllerAfterViewController viewController: UIViewController) -&gt; UIViewController? { currentPageIndex = viewController.view.tag let pageIndex = viewController.view.tag + 1; if pageIndex &gt; 1 { return nil } return viewControllers[pageIndex] as? UIViewController } Now we used Segmented Controll to control PageView. Step 5: Change Segment Using SegmentControll.selectedSegmentIndex to change selected tab. In Step 4, add line : mPageSegment.selectedSegmentIndex = currentPageIndex. Step 6: Click SegmentControll When click SegmentControll many time, we will get the NSInternalInconsistencyException. Because it have an animation when changing Pageview.If the animation isn’t finish, we click SegmentControll again, it throw an NSInternalInconsistencyException. Solutions： Disable Animation 1pageController!.setViewControllers([self.viewControllers[index] as! UIViewController], direction: .Reverse, animated: false, completion:nil) After the animation finished We using second method. Clicking SegmentedControll and setup the variable : enabled is false, when the animation finished, setup true. Control SegmentedControllGoto previous page.direction: UIPageViewControllerNavigationDirection.Forward Goto next page.direction: UIPageViewControllerNavigationDirection.Reverse 12345678910111213141516@IBAction func tapSegment(sender: AnyObject) { mPageSegment.enabled = false; let index = (sender as! UISegmentedControl).selectedSegmentIndex; if (currentPageIndex &lt; index) { pageController!.setViewControllers([self.viewControllers[index] as! UIViewController], direction: .Forward, animated: true, completion:{(isFinished: Bool) in self.mPageSegment.enabled = true; }) } else { pageController!.setViewControllers([self.viewControllers[index] as! UIViewController], direction: .Reverse, animated: true, completion:{(isFinished: Bool) in self.mPageSegment.enabled = true; }) } currentPageIndex = index } Using scroll method, when the animation is finished, set SegmentControll.enabled is true. 12345extension ViewController: UIPageViewControllerDelegate { func pageViewController(pageViewController: UIPageViewController, didFinishAnimating finished: Bool, previousViewControllers: [UIViewController], transitionCompleted completed: Bool) { mPageSegment.enabled = true; }} Source Code 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283import UIKitclass ViewController: UIViewController { @IBOutlet weak var mPageSegment: UISegmentedControl! @IBAction func tapSegment(sender: AnyObject) { mPageSegment.enabled = false; let index = (sender as! UISegmentedControl).selectedSegmentIndex; if (currentPageIndex &lt; index) { pageController!.setViewControllers([self.viewControllers[index] as! UIViewController], direction: .Forward, animated: true, completion:{(isFinished: Bool) in self.mPageSegment.enabled = true; }) } else { pageController!.setViewControllers([self.viewControllers[index] as! UIViewController], direction: .Reverse, animated: true, completion:{(isFinished: Bool) in self.mPageSegment.enabled = true; }) } currentPageIndex = index } var pageController: UIPageViewController! var viewControllers = NSMutableArray() var currentPageIndex : Int! override func viewDidLoad() { super.viewDidLoad() let storyboard = UIStoryboard(name: &quot;Main&quot;, bundle: nil) let firstViewController = storyboard.instantiateViewControllerWithIdentifier(&quot;firstPage&quot;) firstViewController.view.tag = 0; viewControllers.addObject(firstViewController) let secondViewController = storyboard.instantiateViewControllerWithIdentifier(&quot;secondPage&quot;) secondViewController.view.tag = 1; viewControllers.addObject(secondViewController) pageController = UIPageViewController(transitionStyle: .Scroll, navigationOrientation:.Horizontal, options: nil) pageController!.view.frame = CGRectMake(0, mPageSegment.frame.origin.y + mPageSegment.frame.height, view.frame.size.width, view.frame.size.height); currentPageIndex = 0; pageController.setViewControllers([viewControllers.objectAtIndex(currentPageIndex) as! UIViewController], direction: .Forward, animated: false) {(isFinished:Bool) -&gt; Void in } pageController.delegate = self; pageController.dataSource = self; self.addChildViewController(pageController) self.view.addSubview(pageController.view) } override func didReceiveMemoryWarning() { super.didReceiveMemoryWarning() }}extension ViewController: UIPageViewControllerDataSource { func pageViewController(pageViewController: UIPageViewController, viewControllerBeforeViewController viewController: UIViewController) -&gt; UIViewController? { currentPageIndex = viewController.view.tag mPageSegment.selectedSegmentIndex = currentPageIndex; let pageIndex = viewController.view.tag - 1; if pageIndex &lt; 0 { return nil } return viewControllers[pageIndex] as? UIViewController } func pageViewController(pageViewController: UIPageViewController, viewControllerAfterViewController viewController: UIViewController) -&gt; UIViewController? { currentPageIndex = viewController.view.tag mPageSegment.selectedSegmentIndex = currentPageIndex; let pageIndex = viewController.view.tag + 1; if pageIndex &gt; 1 { return nil } return viewControllers[pageIndex] as? UIViewController }}extension ViewController: UIPageViewControllerDelegate { func pageViewController(pageViewController: UIPageViewController, didFinishAnimating finished: Bool, previousViewControllers: [UIViewController], transitionCompleted completed: Bool) { mPageSegment.enabled = true; }} Result","link":"/2016/10/18/2016/2016_10_18-ios-pageviewcontroller_segmentedcontrol/"},{"title":"Android Elevation and shadows","text":"In order to focus object, Android Material Design has three-dimensional qualities that are reflected in use of z-axis and shadows. The elevation value is the relative distance between two surfaces along the z-axis. From the above picture, every menus and sub-menus hasrespective elevation and shadow. For different object, has respective elevation value as follow. Elevation (dp) Component 24 Dialog, Picker 16 Nav drawer, Right drawer, Modal bottom Sheet 12 Floating action button (FAB - pressed) 9 Sub menu (+1dp for each sub menu) 8 Bottom navigation bar, Menu, Card (when picked up), Raised button (pressed state) 6 Floating action button (FAB - resting elevation), Snackbar 4 App Bar 3 Refresh indicator, Quick entry / Search bar (scrolled state) 2 Card (resting elevation) , Raised button (resting elevation), Quick entry / Search bar (resting elevation) 1 Switch App bar : 4dp Raised button Resting state: 2dpPressed state: 8dp For desktop only, raised buttons can have an elevation of:Resting state: 0dpPressed state: 2dp Floating action button (FAB) Resting state: 6dpPressed state: 12dp Card Resting state: 2dpPressed state: 8dp On desktop, cards can have a resting elevation of 0dp and gain an elevation of 8dp on hover. Menus and sub menus Menus: 8dpSub menus: 9dp (+1 dp for each sub menu) Dialogs : 24dp Nav Drawer &amp; Right drawer : 16dp Modal bottom sheet : 16dp Refresh indicator : 3dp Quick entry/Search bar Resting state: 2dpScrolled state: 3dp Snackbar : 6dp Switch : 1dp","link":"/2016/05/25/2016/2016_05_25-android-elevation_shadows/"},{"title":"Android - Firebase Tools","text":"If AndroidStudio has Firebase tool, you can skip this article. Follow steps to install Firebase tool. Step 1: Check the lastest version of Google Repository and Android SDK Tools Step 2: Install Plugins - Firebase Check all Firebase item and click apply then restart AndroidStudio.","link":"/2017/04/19/2017/2017_04_19-android-firebase-install/"},{"title":"Android - Firebase Registration","text":"Introduction Firebase is a cloud service company, that acquisitived by Google at 2014. In the beginning, Google support cloud service that called Cloud to Device Messaging(C2DM).In 2012, stop C2DM service and support a new cloud service that called Google Cloud Messaging (GCM).After acquisitiving Firebase, release Firebase Cloud Messaging (FCM) in 2016. FCM base on GCM support web site, mobile app and cloud service. Register/Login Firebase Account Firebase Homepage Find「Login」, and using google account to login. After login, it shows confirm view, choose 「confirm」.","link":"/2017/04/19/2017/2017_04_19-android-firebase-register/"},{"title":"Android - Develope Firebase Project - Database","text":"We need register Firebase account and setup AndroidStudio tools first. Android - Firebase RegisterationAndroid - Firebase Initialization Step 1: New Firebase Product Click the button「Go to console」 at upper right corner in Firebase homepage. Click「New Project」 Step 2: Import Firebase Add a new module in AndroidStudio, then choose Tools -&gt; Firebase Choose Realtime Database Connect to Firebase &amp; Select your app Step 3: Import Realtime Database Choose「Add the Realtime Database to your app」 Import Success Step 4:Create Database Back to Firebase homepage, choose 「Database」in menu. Click button 「+」and add data. Firebase is not a relational database, it uses 「JSON」format to store data and uses JSON tree structure. We take contact for an example.In database, fill in 「Contact/01/name」and valus is 「Nick」, than click add. Add a new contact「02/name」, and valus is 「Curry」 We can export JSON format. JSON tree as follow, Export File: Step 5:Security Firebase can be read/wrote by verified user. In this example, we let any user could read/write. Please don’t change default settings when releasing product. Choose 「Rule」tab, the default read/write permission is 「auth != null」. We change the value to true. Step 6:Get Firebase Data Back to AndroidStudio, We add a ListView in our layout and setup ListView and ArrayAdapter. 1234567891011121314151617public class MainActivity extends AppCompatActivity { ArrayAdapter&lt;String&gt; fileDBAdapter; @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); ListView list = (ListView) findViewById(R.id.listView); fileDBAdapter = new ArrayAdapter&lt;&gt;(this, android.R.layout.simple_list_item_1, android.R.id.text1); list.setAdapter(fileDBAdapter); }} MainActivity Implements ChildEventListener and functions. In onChildAdded and onChildRemoved function, setup data into ArrayAdapter. 1234567891011@Overridepublic void onChildAdded(DataSnapshot dataSnapshot, String s) { fileDBAdapter.add( String.valueOf(dataSnapshot.child(&quot;name&quot;).getValue()));}@Overridepublic void onChildRemoved(DataSnapshot dataSnapshot) { fileDBAdapter.remove( String.valueOf(dataSnapshot.child(&quot;name&quot;).getValue()));} At OnCreate, setup FirebaseDatabase. 123FirebaseDatabase fireDB = FirebaseDatabase.getInstance();DatabaseReference myRef = fireDB.getReference(&quot;Contact&quot;);myRef.addChildEventListener(this); Result Source Code 123456789101112131415161718192021222324252627282930313233343536373839404142public class MainActivity extends AppCompatActivity implements ChildEventListener { ArrayAdapter&lt;String&gt; fileDBAdapter; @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); ListView list = (ListView) findViewById(R.id.listView); fileDBAdapter = new ArrayAdapter&lt;&gt;(this, android.R.layout.simple_list_item_1, android.R.id.text1); list.setAdapter(fileDBAdapter); FirebaseDatabase fireDB = FirebaseDatabase.getInstance(); DatabaseReference myRef = fireDB.getReference(&quot;聯絡人&quot;); myRef.addChildEventListener(this); } @Override public void onChildAdded(DataSnapshot dataSnapshot, String s) { fileDBAdapter.add( String.valueOf(dataSnapshot.child(&quot;name&quot;).getValue())); } @Override public void onChildRemoved(DataSnapshot dataSnapshot) { fileDBAdapter.remove( String.valueOf(dataSnapshot.child(&quot;name&quot;).getValue())); } @Override public void onChildChanged(DataSnapshot dataSnapshot, String s) { } @Override public void onChildMoved(DataSnapshot dataSnapshot, String s) { } @Override public void onCancelled(DatabaseError databaseError) { }}","link":"/2017/04/20/2017/2017_04_20-android-firebase-database/"},{"title":"Android Face Detector","text":"This article is going to introduce Android API - FaceDetector. EnvironmentDevice : Acrer Iconia Tab 10Version : Android 6.0 (API 23, M) FaceDetectorWe use two object ImageView and Button. ImageView use to show a image that will be detected by FaceDetector API. When clicking Button, FaceDetector API will detect the image and mark the face. ImageView shows a default image. Get the bitmap from ImageView and detect a face. 12345678910111213141516@Overridepublic void onClick(View v) { switch(v.getId()) { case R.id.button: ImageView imageView = findViewById(R.id.imageView); //Get a bitmap from ImageView Bitmap source = ((BitmapDrawable)imageView.getDrawable()).getBitmap(); //detect Bitmap detectMap = detectFace(source); //show a detected botmap imageView.setImageBitmap(detectMap); break; default: break; }} FaceDetector API needs an image with RGB565 format, so we must change to RGB565 format. 1Bitmap source = bitmap.copy(Bitmap.Config.RGB_565, true); Ahter changing format, then using FaceDetector API to detect. 12345678910111213public Bitmap detectFace(Bitmap bitmap) { Bitmap source = bitmap.copy(Bitmap.Config.RGB_565, true); //set the maximun size int MAX_FACES = 5; FaceDetector faceDet = new FaceDetector(source.getWidth(), source.getHeight(), MAX_FACES); FaceDetector.Face[] faceArray = new FaceDetector.Face[MAX_FACES]; faceDet.findFaces(source, faceArray); //Mark found faces drawDetectRect(source, faceArray); return source;} 12345678910111213141516171819202122232425262728293031public void drawDetectRect(Bitmap source, FaceDetector.Face[] faceArray) { int findFaceCount = faceArray.length; if (findFaceCount == 0) { return; } Canvas canvas = new Canvas(source); Paint p = new Paint(); p.setAntiAlias(true); p.setStrokeWidth(4); p.setStyle(Paint.Style.STROKE); p.setColor(Color.RED); PointF pf = new PointF(); RectF rf = new RectF(); for(int i = 0; i &lt; findFaceCount; i++) { FaceDetector.Face face = faceArray[i]; if (null != face) { //Get the center position between left eye and right eye. face.getMidPoint(pf); //eyesDistance: The distance between left eye and right eye. rf.left = pf.x - face.eyesDistance(); rf.right = pf.x + face.eyesDistance(); rf.top = pf.y - face.eyesDistance(); rf.bottom = pf.y + face.eyesDistance(); canvas.drawRect(rf, p); } }} Result","link":"/2018/07/09/2018/2018_07_09-facedetect/"},{"title":"Android package and import aar file","text":"We can import 3rd library in Android project with .jar or .aar file. But .jar file only contains .class files, can’t use resource files.For this reason, we use .aar file that can use resource file. Package .aar file Choose non-activity module. If this module show cann’t run or build. In Edit Configurations, change Launch Options is Nothing. Step 1: Setup Output Mode The gradle definition of apply plugin is 12apply plugin: 'com.android.application' //output mode : apkapply plugin: 'com.android.library' //output mode : library In build.gradle, setup output mode. build.gradle1apply plugin: 'com.android.library' Step 2: delete applicationId** build.gradle1234defaultConfig { //applicationId &quot;com.nickthomas55gmail.testaar&quot; ... } Step 3: generate .aar file Open Gradle Projects (View -&gt; Tool Windows -&gt; Gradle) or click gradle button. In projects root folder, click assemble. After build, We can get the .aar file in build -&gt; outputs -&gt; aar folder. module_name-debug.aarmodule_name-release.aar Import .aar file In Project Structure, choose Import Jar/Aar Package to import .aar file. At dependencies in build.gradle, add the line : compile project *** :module_name*** build.gradle12345dependencies { compile project(':module_name-release') ...} After that, we can use all classes and resources.","link":"/2018/08/03/2018/2018_08_03-aar_packaged_import/"},{"title":"Android GradientDrawable","text":"We will use .9.png to set up background in general.Besides using png, we can use shape tag to set up background. GradientDrawableStatic Method Create xml file in drawable folder. 123456789101112131415161718192021&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;shape xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot; android:shape=&quot;rectangle&quot; &gt; &lt;size android:width=&quot;200dp&quot; android:height=&quot;200dp&quot;/&gt; &lt;corners android:radius=&quot;10dp&quot;/&gt; &lt;gradient android:startColor=&quot;@android:color/white&quot; android:centerColor=&quot;@android:color/holo_red_light&quot; android:endColor=&quot;@android:color/black&quot; android:useLevel=&quot;false&quot; android:angle=&quot;90&quot; android:type=&quot;radial&quot; android:centerX=&quot;0.5&quot; android:centerY=&quot;0.5&quot; android:gradientRadius=&quot;50&quot;/&gt;&lt;/shape&gt; android:shape = [“rectangle” | “oval” | “line” | “ring”] The shape type, default type is rectangle, it can change to oval, line or ring. android:radius Gradient Colorandroid:startColor :android:centerColor :android:endColor: android:useLeveltrue: no gradient colorfalse: has gradient color android:angle The angle for the gradient, in degrees.0 is left to right, 90 is bottom to top.It must be a multiple of 45.Default is 0. android:type : gradient style [linear | radial | sweep] linear (default style) radial sweep android:centerX, android:centerY : The relative position Value is from 0.0 to 1.0. In this case we set the point in center, so android:centerX and android:centerY are 0.5。 android:gradientRadius When android:type=radial，it must setup this item, otherwise you will get the XmlPullParserException. Dynamic Method Setup shage in xml, it is change to GradientDrawable, notShapeDrawable or OvalShape，RoundRectShape and so on. Source code as follows (Kotlin) 123456789101112var imageView = findViewById&lt;ImageView&gt;(R.id.photo)var gd = GradientDrawable()gd.gradientType = GradientDrawable.RECTANGLE //android:shapegd.cornerRadius = 10.0F //android:radius gd.colors = intArrayOf(Color.WHITE, Color.RED, Color.BLACK) //android:centerColor, android:startColor, android:endColorgd.useLevel = false //android:useLevelgd.gradientType = GradientDrawable.RADIAL_GRADIENT //android:type gd.setGradientCenter(0.5F, 0.5F) //android:centerX, android:centerYgd.gradientRadius = 50.0F //android:gradientRadiusimageView.background = gd android:angle is deprecated in Kotlin, you must use GradientDrawable.Orientation.* to implamemnt. 1gd.orientation = GradientDrawable.Orientation.TOP_BOTTOM RunningTime Update We can change background by using GradientDrawable at running time. 123var imageView = findViewById&lt;ImageView&gt;(R.id.photo)var gd = imageView.background as GradientDrawablegd.colors = intArrayOf(Color.WHITE, Color.BLUE, Color.BLACK)","link":"/2018/08/07/2018/2018_08_07-gradientdrawable/"},{"title":"Android Update .aar File","text":"Sometime we use 3rd library to develop application.In previous article, we introduce how to use .jar file or .aar file. When updating .aar file, it isn’t update successfully. We replace the existing .aar file with the new one and use some method like rebuild / sync gradle / File -&gt; Invalidate Caches and Restart to rebuild. But all method are failed. Finally, we use this method that can update successfully. Step 1: Show All Hidden File Step 2: Go to /.idea/libraries folder Step 3: Find the xnl file : Gradle__artifacts_[aar_name].xml and delete it. Step 4: Back to Android Studio，Run File -&gt; Sync Projech with Gradle Files","link":"/2018/08/09/2018/2018_08_09-update_aar/"},{"title":"Set up HttpServer - NanoHttpd","text":"NanoHttp is a light-weight HTTP server designed for embedding system, released under a BSD licence. Step 1: Download .jar NanoHttpd Github Step 2: Import .jar Unzip file and copy .jar file to your project/libs folder. Step 3: Add info in build.gradle build.gradle12345678android { ...}dependencies { ... compile files('libs/nanohttpd-2.3.1.jar')} Step 4: Create custom class Create a custom class and extends NanoHTTPD. NanoHttpServer.java12345public class NanoHttpServer extends NanoHTTPD { public NanoHttpServer(int port) { super(port); }} Step 5: Create NanoHttpServer Created NanoHttpServer and start http server and set up a custom port to communicate with client. MainActivity.java12mHttpServer = new NanoHttpServer(6600);mHttpServer.start(); Step 6: Receive message from client When client is connected, we can receive the message and return response to client. NanoHttpServer.java123456789101112131415161718@Override public Response serve(IHTTPSession session) { String uri = session.getUri(); String method = session.getMethod().name(); String remoteIp = session.getRemoteIpAddress(); NxLog.e(TAG, &quot;uri: &quot; + uri); NxLog.e(TAG, &quot;method: &quot; + method); NxLog.e(TAG, &quot;remoteIp: &quot; + remoteIp); InputStream is = session.getInputStream(); ... String msg = &quot;Send response to client&quot;; return newFixedLengthResponse(msg); } It should be noted that IHTTPSession.getInputStream will never return -1 as end of stream. But we could use a buffer to control loop. When the length of reading stream less than buffer size, than we break this loop. 1234567891011121314try { InputStream is = session.getInputStream(); int buffer_szie = 1024; byte[] buffer = new byte[buffer_szie]; int length = 0; do { length = is.read(buffer); //... } while(length &gt;= buffer_szie );} catch (IOException e) { e.printStackTrace();}","link":"/2019/04/01/2019/2019_04_01-nanohttpd/"},{"title":"Android Camera2","text":"Android 5 (API 21, L) 新增加了Camera2，和之前的Camera使用起來較複雜，但是多了許多功能，支援RAW輸出、調整對焦模式、曝光模式等。 Camera2 首先先了解幾個重要的Class CameraManager : 管理攝影設備，主要功用是獲取所有攝影設備和打開指定的攝影鏡頭。 CameraDevice : 攝影設備，可透過CameraManager.openCamera()來取得。 CameraCaptureSession : 用於處理拍照及預覽工作。 CaptureRequest ：捕捉畫面請求，用來定義輸出緩衝區及顯示 (TextureView or SurfaceView) 我們在畫面中加入一個TextureView，用來預覽攝影鏡頭目前捕捉到的畫面。並設定Listener監聽TextureView是否已設置好。 程式參數 MainActivity.java123456789101112131415161718private TextureView mTextureView;private Size mPreviewSize;private CameraDevice mCameraDevice;private String mCameraId;private ImageReader mImageReader;private CaptureRequest.Builder mCaptureRequestBuilder;private CaptureRequest mCaptureRequest;private CameraCaptureSession mPreviewSession;private static String[] PERMISSIONS_STORAGE = { Manifest.permission.READ_EXTERNAL_STORAGE, Manifest.permission.WRITE_EXTERNAL_STORAGE, Manifest.permission.CAMERA};private static final int RC_HANDLE_CAMERA_PERM = 2; MainActivity: onCreate12mTextureView = findViewById(R.id.textureView);mTextureView.setSurfaceTextureListener(textureListener); 當TextureView設置好之後，再來設置並打開攝影鏡頭。 MainActivity.java123456789TextureView.SurfaceTextureListener textureListener = new TextureView.SurfaceTextureListener() { @Override public void onSurfaceTextureAvailable(SurfaceTexture surface, int width, int height) { //設置攝影鏡頭 setupCamera(width, height); //打開攝影鏡頭。 openCamera(); }}; 利用CamaraManager取得所有攝影鏡頭的資訊，此例子使用後置鏡頭，我們可根據CameraCharacteristics屬性略過前置鏡頭並開啟後置鏡頭。 由於攝影鏡頭支援眾多格式和大小，可由StreamConfigurationMap取得這些屬性。根據TextureView的長寬，設定攝影鏡頭的格式與大小。 MainActivity.java12345678910111213141516171819202122private void setupCamera(int width, int height) { CameraManager manager = (CameraManager) getSystemService(Context.CAMERA_SERVICE); try { //獲取所有攝影設備 String[] cameraList = manager.getCameraIdList(); for (String cameraId: cameraList) { //取得攝影設備屬性 CameraCharacteristics characteristics = manager.getCameraCharacteristics(cameraId); //不擷取前置鏡頭的畫面 if (characteristics.get(CameraCharacteristics.LENS_FACING) == CameraCharacteristics.LENS_FACING_FRONT) continue; //取得StreamConfigurationMap，取得攝影鏡頭支持的所有輸出格式和尺寸 StreamConfigurationMap map = characteristics.get(CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP); //根據TextureView的尺寸設置預覽尺寸 mPreviewSize = getOptimalSize(map.getOutputSizes(SurfaceTexture.class), width, height); mCameraId = cameraId; break; } } catch (CameraAccessException e) { e.printStackTrace(); }} MainActivity.java123456789101112131415161718192021222324//選擇sizeMap中最接近width和height的尺寸private Size getOptimalSize(Size[] sizeMap, int width, int height) { List&lt;Size&gt; sizeList = new ArrayList&lt;&gt;(); for (Size option : sizeMap) { if (width &gt; height) { if (option.getWidth() &gt; width &amp;&amp; option.getHeight() &gt; height) { sizeList.add(option); } } else { if (option.getWidth() &gt; height &amp;&amp; option.getHeight() &gt; width) { sizeList.add(option); } } } if (sizeList.size() &gt; 0) { return Collections.min(sizeList, new Comparator&lt;Size&gt;() { @Override public int compare(Size lhs, Size rhs) { return Long.signum(lhs.getWidth() * lhs.getHeight() - rhs.getWidth() * rhs.getHeight()); } }); } return sizeMap[0];} 根據mCameraId來決定要開啟的鏡頭，並設置CameraDevice.StateCallback監聽狀態。 MainActivity.java123456789101112131415private void openCamera() { CameraManager manager = (CameraManager) getSystemService(Context.CAMERA_SERVICE); try { //檢查權限 if (ActivityCompat.checkSelfPermission(this, Manifest.permission.CAMERA) != PackageManager.PERMISSION_GRANTED) { //請求權限 ActivityCompat.requestPermissions(this, PERMISSIONS_STORAGE, RC_HANDLE_CAMERA_PERM); return; } //根據mCameraId來決定要開啟的鏡頭 manager.openCamera(mCameraId, mStateCallback, null); } catch (CameraAccessException e) { e.printStackTrace(); }} MainActivity.java123456789101112131415161718private final CameraDevice.StateCallback mStateCallback = new CameraDevice.StateCallback() { @Override public void onOpened(CameraDevice camera) { mCameraDevice = camera; //預覽畫面 startPreview(); } @Override public void onDisconnected(@NonNull CameraDevice camera) { Log.e(TAG, &quot;onDisconnected&quot;); } @Override public void onError(@NonNull CameraDevice camera, int error) { Log.e(TAG, &quot;onError: &quot; + error); }}; 設置預覽畫面，將捕捉到的畫面顯示於TextureView中。 MainActivity.java1234567891011121314151617private void startPreview() { SurfaceTexture mSurfaceTexture = mTextureView.getSurfaceTexture(); //設置TextureView的緩衝區大小 mSurfaceTexture.setDefaultBufferSize(mPreviewSize.getWidth(), mPreviewSize.getHeight()); //獲取Surface顯示預覽數據 Surface mSurface = new Surface(mSurfaceTexture); try { //創建預覽請求CaptureRequestBuilder，TEMPLATE_PREVIEW mCaptureRequestBuilder = mCameraDevice.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW); //設置Surface作為預覽顯示界面 mCaptureRequestBuilder.addTarget(mSurface); //創建捕捉畫面，並設置callback mCameraDevice.createCaptureSession(Arrays.asList(mSurface),mCaptureCallback, null); } catch (CameraAccessException e) { e.printStackTrace(); }} 當預覽請求設置好之後，設定Repeat，讓畫面持續更新。 MainActivity.java12345678910111213141516171819private final CameraCaptureSession.StateCallback mCaptureCallback = new CameraCaptureSession.StateCallback() { @Override public void onConfigured(CameraCaptureSession session) { try { //創建捕獲請求 mCaptureRequest = mCaptureRequestBuilder.build(); mPreviewSession = session; //設置反覆捕獲數據，持續畫面更新 mPreviewSession.setRepeatingRequest(mCaptureRequest, null, null); } catch (CameraAccessException e) { e.printStackTrace(); }} @Override public void onConfigureFailed(CameraCaptureSession session) { }}; 執行結果","link":"/2018/07/17/2018/2018_07_17-camera2/"},{"title":"Android loadLibrary - dlopen failed","text":"The library: libcutils.so was working fine till Android Marshmallow (Android 6 (SDK 23)). But my application run on the device with Android Oreo (Android 8 (SDK 26)), get the crash as follow. java.lang.UnsatisfiedLinkError: dlopen failed: library “/system/lib/libcutils.so” is not accessible for the namespace “classloader-namespace” Because Android Nougat (Anroid 7 (SDK 24)) is not currently supported by the Creative SDK. We got several solutions on the Internet. Edit system/etc/public.libraries.txt Add third party library in public.libraries.txt. But this solution is failed on my device. Read library from vendor lib Add third party library in vendor/lib. This solution is success. Device manufactures Android 9 support device manufactures, it can push third party library in system/lib.But I didn’t have this device, not tested yet. In this solution, we must change the library name. ( lib*COMPANYNAME.so)Ex: libgstreamer.so change to libgstreamer.qisda.so And add file: public.libraries-COMPANYNAME.txt in system/etc/ Reference source.android.com","link":"/2019/03/27/2019/2019_03_27-system_loadlibrary_linkerror/"},{"title":"Android TensorFlow Lite Object Recognition","text":"About Face Recognition, many sdks are currently available on the internet, but not free. TensorFlow Lite is a free and lightweight library. This article used object recognition as example. Reference Step 1: Download TensorFlow Model Use MobileNet_v1_1.0_224 Model Link After unzipping, we get the file : mobilenet_v1_1.0_224.tflite. Step 2: Dwonload Label MobileNet_v1_1.0_224 Model has 1001 type, but it doesn’t have tags.We can download the classified tags from this. Link Step 3: Import TensorFlow Lite Add libraries at dependencies in build.gradle. build.gradle12345dependencies { ... implementation 'com.github.bumptech.glide:glide:4.3.1' implementation 'org.tensorflow:tensorflow-lite:0.0.0-nightly'} Inset the text at android to avoid compress the tensor lite model. build.gradle123456android { ... aaptOptions { noCompress &quot;tflite&quot; }} Step 4: Add Model Create assets folder in main folder, and copy mobilenet_v1_1.0_224.tflite and label .txt at here. Designed two button : Import model and analysis image. The source code for import model : loadModeFile : transfer mode file to ByteBuffer，than initialize Interpreter.load_mode : Use Interpreter to analysis image，and setup the thread length (tflite.setNumThreads) MainActivity.java12345678910111213141516171819202122232425262728293031323334353637private final String MODEL_NAME = &quot;mobilenet_v1_1.0_224&quot;;private Interpreter tflite = null;@Overridepublic void onClick(View v) { switch(v.getId()) { case R.id.load_model: load_model(MODEL_NAME); break; ... }}private void load_model(String model) { try { tflite = new Interpreter(loadModelFile(model)); Toast.makeText(MainActivity.this, model + &quot; model load success&quot;, Toast.LENGTH_SHORT).show(); Log.d(TAG, model + &quot; model load success&quot;); tflite.setNumThreads(4); load_result = true; } catch (IOException e) { Toast.makeText(MainActivity.this, model + &quot; model load fail&quot;, Toast.LENGTH_SHORT).show(); Log.d(TAG, model + &quot; model load fail&quot;); load_result = false; e.printStackTrace(); }}private ByteBuffer loadModelFile(String model) throws IOException { AssetFileDescriptor fileDescriptor = getApplicationContext().getAssets().openFd(model + &quot;.tflite&quot;); FileInputStream inputStream = new FileInputStream(fileDescriptor.getFileDescriptor()); FileChannel fileChannel = inputStream.getChannel(); long startOffset = fileDescriptor.getStartOffset(); long declaredLength = fileDescriptor.getDeclaredLength(); return fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength);} Step 5: Insert Label Read label file in onCreate function. MainActivity.java1234567891011121314151617181920@Overrideprotected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); ... readCacheLabelFromLocalFile();}private void readCacheLabelFromLocalFile() { try { AssetManager assetManager = getApplicationContext().getAssets(); BufferedReader reader = new BufferedReader(new InputStreamReader(assetManager.open(LABEL_NAME + &quot;.txt&quot;))); String readLine = null; while ((readLine = reader.readLine()) != null) { resultLabel.add(readLine); } reader.close(); } catch (Exception e) { Log.e(&quot;labelCache&quot;, &quot;error &quot; + e); }} Step 6: Analysis Image predict_image ：Zipping image first, than transfer image to ByteBuffer.Using Interpreter.run() to analysis. get_max_result : Get a classified label with highest probability. MainActivity.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101private List&lt;String&gt; resultLabel = new ArrayList&lt;&gt;();private ImageView mImage;private int[] ddims = {1, 3, 224, 224};private TextView mResult;@Overridepublic void onClick(View v) { switch(v.getId()) { ... case R.id.use_photo: RequestOptions options = new RequestOptions().skipMemoryCache(true).diskCacheStrategy(DiskCacheStrategy.NONE); File file = new File(&quot;/storage/sdcard1/mouse.jpeg&quot;); Uri photoUri = Uri.fromFile(file); Glide.with(MainActivity.this).load(photoUri).apply(options).into(mImage); predict_image(file.getAbsolutePath()); break; default: break; }}private void predict_image(String image_path) { // picture to float array Bitmap bmp = getScaleBitmap(image_path); ByteBuffer inputData = getScaledMatrix(bmp, ddims); try { float[][] labelProbArray = new float[1][1001]; long start = System.currentTimeMillis(); // get predict result tflite.run(inputData, labelProbArray); long end = System.currentTimeMillis(); long time = end - start; float[] results = new float[labelProbArray[0].length]; System.arraycopy(labelProbArray[0], 0, results, 0, labelProbArray[0].length); // show predict result and time int r = get_max_result(results); String show_text = &quot;result：&quot; + r + &quot;\\nname：&quot; + resultLabel.get(r) + &quot;\\nprobability：&quot; + results[r] + &quot;\\ntime：&quot; + time + &quot;ms&quot;; mResult.setText(show_text); } catch (Exception e) { e.printStackTrace(); }}private Bitmap getScaleBitmap(String filePath) { BitmapFactory.Options opt = new BitmapFactory.Options(); opt.inJustDecodeBounds = true; BitmapFactory.decodeFile(filePath, opt); int bmpWidth = opt.outWidth; int bmpHeight = opt.outHeight; int maxSize = 500; // compress picture with inSampleSize opt.inSampleSize = 1; while (true) { if (bmpWidth / opt.inSampleSize &lt; maxSize || bmpHeight / opt.inSampleSize &lt; maxSize) { break; } opt.inSampleSize *= 2; } opt.inJustDecodeBounds = false; return BitmapFactory.decodeFile(filePath, opt);}private ByteBuffer getScaledMatrix(Bitmap bitmap, int[] ddims) { ByteBuffer imgData = ByteBuffer.allocateDirect(ddims[0] * ddims[1] * ddims[2] * ddims[3] * 4); imgData.order(ByteOrder.nativeOrder()); // get image pixel int[] pixels = new int[ddims[2] * ddims[3]]; Bitmap bm = Bitmap.createScaledBitmap(bitmap, ddims[2], ddims[3], false); bm.getPixels(pixels, 0, bm.getWidth(), 0, 0, ddims[2], ddims[3]); int pixel = 0; for (int i = 0; i &lt; ddims[2]; ++i) { for (int j = 0; j &lt; ddims[3]; ++j) { final int val = pixels[pixel++]; imgData.putFloat(((((val &gt;&gt; 16) &amp; 0xFF) - 128f) / 128f)); imgData.putFloat(((((val &gt;&gt; 8) &amp; 0xFF) - 128f) / 128f)); imgData.putFloat((((val &amp; 0xFF) - 128f) / 128f)); } } if (bm.isRecycled()) { bm.recycle(); } return imgData;}private int get_max_result(float[] result) { float probability = result[0]; int r = 0; for (int i = 0; i &lt; result.length; i++) { if (probability &lt; result[i]) { probability = result[i]; r = i; } } return r;} Result","link":"/2019/04/10/2019/2019_04_10-tensorflow_lite_object_recognition/"},{"title":"Android Network Neighborhood - Jcifs-ng","text":"Uploading or downloading file at local network between Android and Windows by using smb socket. Android app can use Jcifs library to access file which is in the Windows system. But Jcifs only support smb 1. If Windows system only support smb2 or smb3, we must use other library, like smbj or jcifs-ng. Because smbj library just for Android SDK Platform 26 (Android O, Android 8), so this article used jcifs-ng to implement. Step 1: Import Jcifs -ng In Jcifs-ng website，add as follow in build.gradle build.gradle12345&lt;dependency&gt; &lt;groupId&gt;eu.agno3.jcifs&lt;/groupId&gt; &lt;artifactId&gt;jcifs-ng&lt;/artifactId&gt; &lt;version&gt;2.1.2&lt;/version&gt;&lt;/dependency&gt; also change to build.gradle12345678android { ...}dependencies { ... compile 'eu.agno3.jcifs:jcifs-ng:2.1.2'} Step 2: Access Remote File 1234567891011121314151617181920212223String userName = &quot;user&quot;;String password = &quot;1234&quot;;String remoteFile = &quot;/files/test.csv&quot;;String remoteURL = &quot;smb://nickpublicpc&quot;;CIFSContext baseCxt = new BaseContext(new PropertyConfiguration(System.getProperties()));NtlmPasswordAuthenticator auth = new NtlmPasswordAuthenticator(userName, password);CIFSContext ct = baseCxt.withCredentials(auth);SmbFile smbFile = new SmbFile(remoteURL + remoteFile, ct);SmbFileInputStream inputSmbFileStream = new SmbFileInputStream(smbFile);File localFile = new File(filePath);FileOutputStream outputFileStream = new FileOutputStream(localFile);byte[] buffer = new byte[4096];int length = 0;while ((length = inputSmbFileStream.read(buffer)) &gt; 0) { outputFileStream.write(buffer, 0, length);}outputFileStream.close();inputSmbFileStream.close(); As mentioned above, we can access file at the local network, but Jcifs-ng support smb3 partially.","link":"/2019/04/09/2019/2019_04_09-jcifs_ng/"},{"title":"Android Baidu Text To Speech","text":"Text To Speech (TTS) converts text into human-like speech. Baidu TTS is a free TTS SDK，we use this sdk to develop TTS app. Step 1: Create Application First, registered account at Baidu.After that，log in to the Baidu Voice Developer Platform and create an application. choose speech technology choose create application input information， package name must be match the package name of your app. Step 2: Download SDK and library Check download sdk button in left hand side, then choose speech synthesis and download SDK for android. Unzip sdk than copy Baidu-TTS-Android-2.3.5.20180713_6101c2a/app/src/main/jniLibs/armeabi folder into your project jniLibs folder. And copy Baidu-TTS-Android-2.3.5.20180713_6101c2a/app/libs/com.baidu.tts_2.3.2.jar into your project libs folder. Step 3: Import jar in build.gradle, add as follow build.gradle1234dependencies { ... compile files('libs/com.baidu.tts_2.3.2.jar')} Step 4: Init TTS init SpeechSynthesizer 1234private SpeechSynthesizer mSpeechSynthesizer;mSpeechSynthesizer = SpeechSynthesizer.getInstance();mSpeechSynthesizer.setContext(this); setup TTS Listener 12345678910111213141516171819202122232425262728public class MainActivity extends AppCompatActivity implements SpeechSynthesizerListener { private void initTTS() { ... mSpeechSynthesizer.setSpeechSynthesizerListener(this); } @Override public void onSynthesizeStart(String s) { } @Override public void onSynthesizeDataArrived(String s, byte[] bytes, int i) { } @Override public void onSynthesizeFinish(String s) { } @Override public void onSpeechStart(String s) { } @Override public void onSpeechProgressChanged(String s, int i) { } @Override public void onSpeechFinish(String s) { } @Override public void onError(String s, SpeechError speechError) { }} Step 5: set AppId, AppKey 和 AppSecretKey In Baidu website, this application is built, you will get AppId, AppKey and AppSecretKey. 12int result = mSpeechSynthesizer.setAppId(appId);result = mSpeechSynthesizer.setApiKey(appKey, secretKey); Step 6: Verify and Download authorized file TtsMode.ONLINE : pure online, download authorized file automatically.TtsMode.MIX : From online fusion, online priority; 12345678910private boolean checkAuth() { AuthInfo authInfo = mSpeechSynthesizer.auth(ttsMode); if (!authInfo.isSuccess()) { String errorMsg = authInfo.getTtsError().getDetailMessage(); return false; } else { Log.i(TAG, &quot;checkAuth success!&quot;); return true; }} Step 7: Import TTS Model copy Baidu-TTS-Android-2.3.5.20180713_6101c2a/app/src/main/assets into your_project/src/main/assets Before using TTS, copy model files into sd card folder. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869private String MODEL_FILENAME ; private String TEXT_FILENAME ; private static final String SPEECH_FEMALE_MODEL_NAME = &quot;bd_etts_common_speech_f7_mand_eng_high_am-mix_v3.0.0_20170512.dat&quot;; private static final String TEXT_MODEL_NAME = &quot;bd_etts_text.dat&quot;; @Overrideprotected void onResume() { super.onResume(); copyModelFileToSD(); initTTS();}private void copyModelFileToSD() { String folder = MainActivity.this.getFilesDir().getAbsolutePath(); MODEL_FILENAME = folder + &quot;/&quot; + TEXT_MODEL_NAME; TEXT_FILENAME = folder + &quot;/&quot; + SPEECH_FEMALE_MODEL_NAME; InputStream is = null; FileOutputStream fos = null; try { Context context = MainActivity.this.getApplicationContext(); File textFile = new File(TEXT_FILENAME); File modelFile = new File(MODEL_FILENAME); if (!textFile.exists()) { textFile.createNewFile(); is = context.getAssets().open(TEXT_MODEL_NAME); fos = new FileOutputStream(textFile); copyFile(is, fos); } else { //ignore } if (!modelFile.exists()) { modelFile.createNewFile(); is = context.getAssets().open(SPEECH_FEMALE_MODEL_NAME); fos = new FileOutputStream(modelFile); copyFile(is, fos); } else { //ignore } } catch (IOException e) { Log.e(TAG, &quot;Error: &quot; + e.toString()); } finally { closeObject(is); closeObject(fos); }}private void copyFile(InputStream is, FileOutputStream fos) throws IOException { byte[] buffer = new byte[2048]; int byteCount = 0; while((byteCount=is.read(buffer))!=-1) { fos.write(buffer, 0, byteCount); } fos.flush();}private void closeObject(Closeable obj) { try { if (null != obj) { obj.close(); } } catch (IOException e) { Log.e(TAG, &quot;Error: &quot; + e.toString()); }} After check authorization, setup parameters for speach model. 12345678910111213141516private void setupParam() { mSpeechSynthesizer.setParam(SpeechSynthesizer.PARAM_TTS_TEXT_MODEL_FILE, TEXT_FILENAME); mSpeechSynthesizer.setParam(SpeechSynthesizer.PARAM_TTS_SPEECH_MODEL_FILE, MODEL_FILENAME); //Voice type, 0 : female, 1:male, 2:Speical male, 3: emotion male, 4:child mSpeechSynthesizer.setParam(SpeechSynthesizer.PARAM_SPEAKER, &quot;0&quot;); //Volumn: 0 ~ 9 mSpeechSynthesizer.setParam(SpeechSynthesizer.PARAM_VOLUME, &quot;9&quot;); //Speed: 0~9 mSpeechSynthesizer.setParam(SpeechSynthesizer.PARAM_SPEED, &quot;4&quot;); //Pitch: 0 ~ 9 mSpeechSynthesizer.setParam(SpeechSynthesizer.PARAM_PITCH, &quot;4&quot;); //Request Mode mSpeechSynthesizer.setParam(SpeechSynthesizer.PARAM_MIX_MODE, SpeechSynthesizer.MIX_MODE_DEFAULT); } MIX_MODE_DEFAULT: If wifi connection, using TtsMode.ONLINE, else using TtsMode.MIX. In TtsMode.ONLINE, if request time more than 6 second, it will change to TtsMode.MIX mode automatically. MIX_MODE_HIGH_SPEED_SYNTHESIZE_WIFI: the same as MIX_MODE_DEFAULT，but request time more than 1.2 second, it will change to TtsMode.MIX mode automatically. MIX_MODE_HIGH_SPEED_NETWORK: can use 3G/4G or Wifi, but request time more than 1.2 second, it will change to TtsMode.MIX mode automatically. Initialize TTS flow as follow 1234567891011121314151617181920private void initTTS() { mSpeechSynthesizer = SpeechSynthesizer.getInstance(); mSpeechSynthesizer.setContext(this); mSpeechSynthesizer.setSpeechSynthesizerListener(this); int result = mSpeechSynthesizer.setAppId(appId); result = mSpeechSynthesizer.setApiKey(appKey, secretKey); if (!checkAuth()) { return; } setupParam(); result = mSpeechSynthesizer.loadModel(TEXT_FILENAME, MODEL_FILENAME); result = mSpeechSynthesizer.initTts(TtsMode.MIX); if (result != 0) { Log.e(TAG, &quot;init failed&quot;); } else { Log.e(TAG, &quot;init success&quot;); }} Step 8: Speech If speach text immediately, you can use speak api.Using synthesize api can synthesis text, than using speak api to read out. 12String text = &quot;test baidu TTS&quot;;mSpeechSynthesizer.speak(text);","link":"/2019/04/12/2019/2019_04_12-baidu_tts/"},{"title":"Android onConfigurationChanged not called for Landscape and Reverselandscape","text":"Override onConfigurationChanged method to detect orientation changes, but receiving event only when landscape change to portrait vise versa. So when landscape changes to reverse landscape, onConfigurationChanged method can’t receive event. onConfigurationChanged How to use onConfigurationChanged method as follows. Add android:configChanges in tag of AndroidManifest.xml. AndroidManifest.xml123456&lt;application ... &gt; &lt;activity android:name=&quot;.MainActivity&quot; android:screenOrientation=&quot;sensorLandscape&quot; android:configChanges=&quot;orientation|screenSize|keyboardHidden&quot;/&gt;&lt;/application&gt; Add Override function : onConfigurationChanged in MainActivity.java. AndroidManifest.xml123override fun onConfigurationChanged(newConfig: Configuration?) { super.onConfigurationChanged(newConfig)} This method can’t figure out if it’s Landscape or Landscape-reverse. But we can use Rotation change to figure out Landscape or Landscape-reverse. Rotation Changed Listener Step 1: Create callback : RotationCallback Add kotlin interface : RotationCallback RotationCallback.kt123interface RotationCallback { fun onRotationChanged(lastRotation: Int, newRotation: Int)} Step 2: Create Listerner : RotationListener Add kotlin class : RotationListener mOrientationEventListener listened the rotation changes，and send event to top level by mCallback object. RotationListener.kt123456789101112131415161718192021222324252627282930313233343536class RotationListener { private var mOrientationEventListener: OrientationEventListener? = null private var mCallback: RotationCallback? = null private var lastRotation: Int = 0 constructor(callback: RotationCallback) { mCallback = callback } fun listen(context: Context) { mOrientationEventListener = object : OrientationEventListener(context, SensorManager.SENSOR_DELAY_NORMAL) { override fun onOrientationChanged(orientation: Int) { val localWindowManager = context.getSystemService(Context.WINDOW_SERVICE) as WindowManager if (null != localWindowManager &amp;&amp; null != mCallback) { val newRotation = localWindowManager.defaultDisplay.rotation if (newRotation != lastRotation) { mCallback!!.onRotationChanged(lastRotation, newRotation) lastRotation = newRotation } } } } mOrientationEventListener!!.enable() lastRotation = (context.getSystemService(Context.WINDOW_SERVICE) as WindowManager).defaultDisplay.rotation } fun stop() { if (null != mOrientationEventListener) { mOrientationEventListener!!.disable() } mOrientationEventListener = null mCallback = null }} Step 3: Register/Unregister listener MainActivity implemented RotationCallback and onRotationChanged function，and setup rotation listener at onCreate step and unregister it at onDestroy step. MainActivity.kt123456789101112131415161718192021222324252627class MainActivity : AppCompatActivity(), RotationCallback { private val TAG = &quot;MainActivity &quot; private var mRotationListener : RotationListener? = null override fun onCreate(savedInstanceState: Bundle?) { super.onCreate(savedInstanceState) setContentView(R.layout.activity_main) mRotationListener = RotationListener(this) mRotationListener!!.listen(this.applicationContext) } override fun onDestroy() { super.onDestroy() Log.e(TAG, &quot;onDestroy()&quot;) mRotationListener!!.stop() mRotationListener = null } //RotationCallback override fun onRotationChanged(lastRotation: Int, newRotation: Int) { Log.d(TAG, &quot;onRotationChanged: last &quot; + (lastRotation) +&quot; new &quot; + (newRotation)); }} By this method, it can figure out landscape and reverselandscape.","link":"/2019/11/21/2019/2019_11_21-reverselandscape-event/"},{"title":"Android ImageView Transparent Background","text":"The source bitmap for ImageView has transparent color, we must set the background color of this ImageView to transparent color. If not, an ImageView will overlap with another ImageView. Those are some methods to set transparent color. Static Setting In xml, set background “#00000000” activity.xml12345&lt;ImageView android:layout_width=&quot;218dp&quot; android:layout_height=&quot;247dp&quot; android:src=&quot;@drawable/test2&quot; android:background=&quot;#00000000&quot;/&gt; Also can use android color : transparent activity.xml12345&lt;ImageView android:layout_width=&quot;218dp&quot; android:layout_height=&quot;247dp&quot; android:src=&quot;@drawable/test2&quot; aandroid:background=&quot;@android:color/transparent&quot;/&gt; Dynamic Setting In program, we could use API: setBackgroundColor. MainActivity.java12var imageView = findViewById&lt;ImageView&gt;(R.id.test1)imageView.setBackgroundColor(Color.parseColor(&quot;#00000000&quot;)) Or use Color.TRANSPARENT MainActivity.java12var imageView = findViewById&lt;ImageView&gt;(R.id.test1)imageView.setBackgroundColor(Color.TRANSPARENT) Result","link":"/2019/12/26/2019/2019_12_26-imageview-transparent-background/"},{"title":"Hexo - Icarus using Google AdSense","text":"There are several ways to making money with your blog. One way is Google AdSense.Most blogs use Next theme to embed Google AdSense, but my blog used Icarus theme. After some research, I found a way to embed Google AdSense with Icarus theme.Steps as follow. Only for Icarus 2.X Step 1: Register Google AsSense account Before register，your blog must have enough articles. Visit the Google AdSense sign-up page and sign in with your existing Google account. Enter the full URL of your website’s home page. Fill in the name of the blog, country of origin and agree to the terms and conditions of use of the platform. Step 2: Verify Blog After registered, Google will verify your blog. Google AdSense will send a script ，add this script in the tag content. (/hexo/theme/hexo-theme-icarus/layout/layout.ejs) layout.ejs1234567&lt;!DOCTYPE html&gt;&lt;html &lt;%- has_config('language') ? ' lang=&quot;' + get_config('language').substring(0, 2) + '&quot;' : '' %&gt;&gt;&lt;head&gt; &lt;%- _partial('common/head') %&gt; &lt;script data-ad-client=&quot;ca-pub-xxxxxxxxxx&quot; async src=&quot;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&quot;&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; ... &lt;/body&gt; After that, check verify button in Google AdSense website. At the end of the registration process, Google will send an envelope to your address with a verification code. This may take up to three days or a week. Step 3: Add Ads After verified, we use the type「Block of links」to embed on my blog. Goolge AdSense will give you a script. Add this script in your card widget. Ex: Footer : /hexo/theme/hexo-theme-icarus/layout/common/footer.ejs 1234567891011121314151617&lt;footer class=&quot;footer&quot;&gt; &lt;div class=&quot;container&quot;&gt; &lt;div class=&quot;level&quot;&gt; &lt;/div&gt; &lt;script async src=&quot;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&quot;&gt;&lt;/script&gt; &lt;!-- Landscape Ads --&gt; &lt;ins class=&quot;adsbygoogle&quot; style=&quot;display:block&quot; data-ad-client=&quot;ca-pub-xxxxxxxx&quot; data-ad-slot=&quot;xxxxxxx&quot; data-ad-format=&quot;auto&quot; data-full-width-responsive=&quot;true&quot;&gt;&lt;/ins&gt; &lt;script&gt; (adsbygoogle = window.adsbygoogle || []).push({}); &lt;/script&gt; &lt;/div&gt;&lt;/footer&gt; Profile : /hexo/theme/hexo-theme-icarus/layout/widget/profile.ejs 123456789101112131415&lt;div class=&quot;card widget&quot;&gt; &lt;div class=&quot;card-content&quot;&gt; &lt;script async src=&quot;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&quot;&gt;&lt;/script&gt; &lt;!-- Square Ads --&gt; &lt;ins class=&quot;adsbygoogle&quot; style=&quot;display:block&quot; data-ad-client=&quot;ca-pub-xxxxxxxxx&quot; data-ad-slot=&quot;xxxxx&quot; data-ad-format=&quot;auto&quot; data-full-width-responsive=&quot;true&quot;&gt;&lt;/ins&gt; &lt;script&gt; (adsbygoogle = window.adsbygoogle || []).push({}); &lt;/script&gt; &lt;/div&gt;&lt;/div&gt; Link : /hexo/theme/hexo-theme-icarus/layout/widget/link.ejs 123456789101112131415&lt;div class=&quot;card widget&quot;&gt; &lt;div class=&quot;card-content&quot;&gt; &lt;script async src=&quot;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&quot;&gt;&lt;/script&gt; &lt;!-- Square Ads --&gt; &lt;ins class=&quot;adsbygoogle&quot; style=&quot;display:block&quot; data-ad-client=&quot;ca-pub-xxxxxxxxx&quot; data-ad-slot=&quot;xxxxx&quot; data-ad-format=&quot;auto&quot; data-full-width-responsive=&quot;true&quot;&gt;&lt;/ins&gt; &lt;script&gt; (adsbygoogle = window.adsbygoogle || []).push({}); &lt;/script&gt; &lt;/div&gt;&lt;/div&gt; After 30 min. , you will see the Ads in your blog.","link":"/2019/10/25/2019/2019_10_25-icarus-google-adsense/"}],"tags":[{"name":"NavigationBar","slug":"NavigationBar","link":"/tags/NavigationBar/"},{"name":"下拉式選單","slug":"下拉式選單","link":"/tags/%E4%B8%8B%E6%8B%89%E5%BC%8F%E9%81%B8%E5%96%AE/"},{"name":"PageView","slug":"PageView","link":"/tags/PageView/"},{"name":"shadow","slug":"shadow","link":"/tags/shadow/"},{"name":"Firebase","slug":"Firebase","link":"/tags/Firebase/"},{"name":"人臉偵測","slug":"人臉偵測","link":"/tags/%E4%BA%BA%E8%87%89%E5%81%B5%E6%B8%AC/"},{"name":"aar","slug":"aar","link":"/tags/aar/"},{"name":"漸變效果","slug":"漸變效果","link":"/tags/%E6%BC%B8%E8%AE%8A%E6%95%88%E6%9E%9C/"},{"name":"NanoHttpd","slug":"NanoHttpd","link":"/tags/NanoHttpd/"},{"name":"Camera","slug":"Camera","link":"/tags/Camera/"},{"name":"dlopen failed","slug":"dlopen-failed","link":"/tags/dlopen-failed/"},{"name":"TensorFlow","slug":"TensorFlow","link":"/tags/TensorFlow/"},{"name":"JCIFS","slug":"JCIFS","link":"/tags/JCIFS/"},{"name":"TTS","slug":"TTS","link":"/tags/TTS/"},{"name":"onConfigurationChanged","slug":"onConfigurationChanged","link":"/tags/onConfigurationChanged/"},{"name":"ImageView","slug":"ImageView","link":"/tags/ImageView/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"icarus","slug":"icarus","link":"/tags/icarus/"}],"categories":[{"name":"iOS","slug":"iOS","link":"/categories/iOS/"},{"name":"Android","slug":"Android","link":"/categories/Android/"},{"name":"NavigationBar","slug":"iOS/NavigationBar","link":"/categories/iOS/NavigationBar/"},{"name":"Spinner","slug":"iOS/Spinner","link":"/categories/iOS/Spinner/"},{"name":"PageViewController","slug":"iOS/PageViewController","link":"/categories/iOS/PageViewController/"},{"name":"GradientDrawable","slug":"Android/GradientDrawable","link":"/categories/Android/GradientDrawable/"},{"name":"Z-Order","slug":"Android/Z-Order","link":"/categories/Android/Z-Order/"},{"name":"aar","slug":"Android/aar","link":"/categories/Android/aar/"},{"name":"NanoHttpd","slug":"Android/NanoHttpd","link":"/categories/Android/NanoHttpd/"},{"name":"Camera","slug":"Android/Camera","link":"/categories/Android/Camera/"},{"name":"Firebase","slug":"Android/Firebase","link":"/categories/Android/Firebase/"},{"name":"TensorFlow","slug":"Android/TensorFlow","link":"/categories/Android/TensorFlow/"},{"name":"JCIFS","slug":"Android/JCIFS","link":"/categories/Android/JCIFS/"},{"name":"TTS","slug":"Android/TTS","link":"/categories/Android/TTS/"},{"name":"onConfigurationChanged","slug":"Android/onConfigurationChanged","link":"/categories/Android/onConfigurationChanged/"},{"name":"FaceDetector","slug":"Android/FaceDetector","link":"/categories/Android/FaceDetector/"},{"name":"ImageView","slug":"Android/ImageView","link":"/categories/Android/ImageView/"},{"name":"Hexo","slug":"Hexo","link":"/categories/Hexo/"},{"name":"Icarus","slug":"Hexo/Icarus","link":"/categories/Hexo/Icarus/"}]}